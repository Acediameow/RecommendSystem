{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入相应的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from operator import itemgetter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固定随机数种子，保证模型的可复现性\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 1024\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(feature, target, batch_size, shuffle=True):\n",
    "    class MyDataset(data.Dataset):\n",
    "        def __init__(self, feature, target):\n",
    "            self.feature = feature\n",
    "            self.target = target\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            m, n = self.feature[index], self.target[index]\n",
    "            return m, n\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.feature)\n",
    "\n",
    "    bdata = data.DataLoader(MyDataset(feature, target), batch_size = batch_size, shuffle = shuffle)\n",
    "    return bdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, usecols=[0, 1, 11, 3, 4], header = 0, names = ['id', 'click', 'C1', 'banner', 'device_id'])\n",
    "    \n",
    "    # 处理\n",
    "    df[\"item_id\"] = df[\"id\"]\n",
    "    df_user = pd.get_dummies(df, columns=['C1', 'banner'])\n",
    "    df_user1 = df_user.drop(columns=['item_id'])\n",
    "    user_feature = df_user1.columns.values.tolist()\n",
    "    cols = user_feature\n",
    "    cols.remove('device_id')\n",
    "    cols.remove('id')\n",
    "    cols.remove('click')\n",
    "    \n",
    "    # get field\n",
    "    field_index = {} \n",
    "    feature2field = {}\n",
    "    other_idxs = []\n",
    "    \n",
    "    for idx, col in enumerate(cols):\n",
    "        infos = col.split('_')\n",
    "        if len(infos) == 2:\n",
    "            field = infos[0]\n",
    "            field_index[field] = field_index.get(field, len(field_index))\n",
    "            feature2field[idx] = field_index[field]\n",
    "        if len(infos) == 1:\n",
    "            other_idxs.append(idx)\n",
    "            \n",
    "    for idx in other_idxs:\n",
    "        feature2field[idx] = len(field_index)\n",
    "        \n",
    "    # merge得到相应的数据\n",
    "    df_data = pd.read_csv(path, usecols =[0, 1 , 11],header = 0,names = ['id', 'click', 'device_id'])\n",
    "    df_data['id'] = df['id']\n",
    "    train, test = train_test_split(df_data, test_size = 0.1, random_state = 666)\n",
    "    \n",
    "    label_l = ['id', 'click', 'device_id']\n",
    "    df_train = train.merge(df_user1, on = label_l, how = 'left')\n",
    "    df_test= test.merge(df_user1, on = label_l, how = 'left')\n",
    "    \n",
    "    # 转换label\n",
    "    dic = {}\n",
    "    label_set = sorted(set(df_train['click']) | set(df_test['click']))\n",
    "    \n",
    "    for label in label_set:\n",
    "        dic[label] = dic.get(label, len(dic))\n",
    " \n",
    "    df_train['click'] = df_train[\"click\"].apply(lambda x: 1 if int(x) == 1 else 0)\n",
    "    df_test['click'] = df_test[\"click\"].apply(lambda x: 1 if int(x) == 1 else 0)\n",
    " \n",
    "    # 转换格式\n",
    "    train_labels = np.array(df_train['click'].astype(np.int32))\n",
    "    test_labels = np.array(df_test['click'].astype(np.int32))\n",
    "    \n",
    "    return df_data, df_test, df_train[cols].values, train_labels, df_test[cols].values, test_labels, feature2field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFM_layer(nn.Module):\n",
    "    def __init__(self, field_dic, fea_num, reg_l1=0.01, reg_l2=0.01, class_num=1, latent_factor_dim=10):\n",
    "        super(FFM_layer, self).__init__()\n",
    "        self.reg_l1 = reg_l1\n",
    "        self.reg_l2 = reg_l2\n",
    "        self.fea_num = fea_num\n",
    "        self.field_dic = field_dic\n",
    "        self.linear = nn.Linear(fea_num, class_num)   \n",
    "        self.v = nn.Parameter(torch.randn(fea_num, len(field_dic), latent_factor_dim, class_num)) # 主要是看明白这个v的构造，多个field的维度\n",
    " \n",
    "    def forward(self, x):\n",
    "        linear_part = self.linear(x)\n",
    " \n",
    "        p = 0.0\n",
    "        for i in range(0, self.fea_num):\n",
    "            for j in range(i + 1, self.fea_num):\n",
    "                v_ifj = self.v[i, self.field_dic[j], :, :]\n",
    "                v_jfi = self.v[j, self.field_dic[i], :, :]\n",
    " \n",
    "                xij = torch.unsqueeze(x[:, i] * x[:, j], dim = 1)\n",
    "                v_ijji = torch.unsqueeze(torch.sum(v_ifj * v_jfi, dim = 0), dim = 0)  \n",
    "                p += torch.mm(xij, v_ijji)\n",
    " \n",
    "        output = linear_part + p\n",
    "    \n",
    "        output = torch.log_softmax(output, dim = 1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for idx, (x, y) in enumerate(train):\n",
    "        x = x.to(device, dtype = torch.float32)\n",
    "        y = y.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = F.nll_loss(output, y)\n",
    " \n",
    "        loss1 = 0\n",
    "        for param in model.parameters():\n",
    "            loss1 += model.reg_l1 * torch.sum(torch.abs(param))\n",
    "            loss1 += model.reg_l2 * torch.sum(torch.pow(param, 2))\n",
    "        loss += loss1\n",
    " \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, device, test):\n",
    "    loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test:\n",
    "            x = x.to(device, dtype = torch.float32)\n",
    "            y = y.to(device).long()\n",
    "            output = model(x)\n",
    "            \n",
    "            loss += F.nll_loss(output, y, reduction = 'sum').item()\n",
    " \n",
    "            loss1 = 0\n",
    "            for param in model.parameters():\n",
    "                loss1 += model.reg_l1 * torch.sum(torch.abs(param))\n",
    "                loss1 += model.reg_l2 * torch.sum(torch.pow(param, 2))\n",
    "            loss += loss1\n",
    " \n",
    "            pred = output.max(1, keepdim = True)[1]\n",
    "            corr += pred.eq(y.view_as(pred)).sum().item()\n",
    "    \n",
    "    loss /= len(test.dataset)\n",
    "    print(\"loss:\" + str(loss.item()) + \" acc:\" + str(100. * corr / len(test.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(model, user_id, device, df_test, data):\n",
    "    dic = {}\n",
    "    l = []\n",
    "    labels = []\n",
    "    predicts = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            x = x.to(device, dtype = torch.float32)\n",
    "            y = y.to(device).long()\n",
    "            pre = model(x).max(1, keepdim = True)[0]\n",
    "            \n",
    "            for i in range(len(pre)):\n",
    "                l.append([list(df_test['device_id'])[i], list(df_test['id'])[i], pre[i], y[i]])   \n",
    "            \n",
    "            for user, item, pre, label in l:\n",
    "                if int(label) == 1: #如果点击过就跳过 \n",
    "                    continue\n",
    "                dic.setdefault(user, {})\n",
    "                pre = float(pre)\n",
    "                dic[user_id].setdefault(item, pre)\n",
    "\n",
    "    l = list(sorted(dic[user_id].items(), key = itemgetter(1), reverse = True)[:5])\n",
    "    \n",
    "    return [x[0] for x in l]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/avazu/ctr_data.csv'\n",
    "df_data, test, x_train, y_train, x_test, y_test, feature2field = load_dataset(path)\n",
    "\n",
    "x_train = preprocessing.scale(x_train, with_mean=True, with_std=True)\n",
    "x_test = preprocessing.scale(x_test, with_mean=True, with_std=True)\n",
    "\n",
    "l1 = [x for x in y_train]\n",
    "l2 = [x for x in y_test]\n",
    "l = set(l1 + l2)\n",
    "class_num = len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:3.6003482341766357 acc:15.5\n",
      "loss:2.9328343868255615 acc:15.5\n",
      "loss:2.270759344100952 acc:69.3\n",
      "loss:1.6151325702667236 acc:69.3\n",
      "loss:1.0864793062210083 acc:72.5\n",
      "loss:0.80668044090271 acc:72.5\n",
      "loss:0.6866648197174072 acc:73.7\n",
      "loss:0.6335725784301758 acc:84.9\n",
      "loss:0.5984730124473572 acc:84.9\n",
      "loss:0.5693916082382202 acc:84.9\n"
     ]
    }
   ],
   "source": [
    "# FFM模型\n",
    "model = FFM_layer(field_dic = feature2field, fea_num = x_train.shape[1], reg_l1 = 0.01, reg_l2 = 0.01, class_num = class_num, latent_factor_dim = 10).to(device)\n",
    " \n",
    "# 定义损失函数还有优化器\n",
    "optm = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_data = get_data(x_train, y_train, batch_size, shuffle = True)\n",
    "test_data = get_data(x_test, y_test, batch_size, shuffle = False)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_model(model, device, train_data, optm, epoch)\n",
    "    test_model(model, device, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10977840500307600000, 11371461600980200000, 10641663383298100000, 11010988566923400000, 11203583363195000000]\n"
     ]
    }
   ],
   "source": [
    "l = recommend(model, \"a99f214a\", device, test, test_data)\n",
    "print(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

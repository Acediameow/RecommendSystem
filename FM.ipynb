{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入相应的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from operator import itemgetter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固定随机数种子，保证模型的可复现性\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 1024\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(features, labels, batch_size, shuffle=True):\n",
    "    class MyDataset(data.Dataset):\n",
    "        def __init__(self, features, labels):\n",
    "            self.features = features\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, index):  # tensor\n",
    "            row_data, target = self.features[index], self.labels[index]\n",
    "            return row_data, target\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.features)\n",
    "\n",
    "    batch_loader = data.DataLoader(MyDataset(features, labels), batch_size=batch_size, shuffle=shuffle)\n",
    "    return batch_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, usecols = [0, 1, 11, 3, 4], header = 0, names = ['id', 'click', 'C1', 'banner', 'device_id'])\n",
    "    # 处理\n",
    "    df[\"user_id\"] = 0\n",
    "    df[\"item_id\"] = df[\"id\"]\n",
    "    l = list(set(df['device_id']))\n",
    "    for i in l:\n",
    "        for j in range(0, len(df['device_id'])):\n",
    "            if df['device_id'][j] == i:\n",
    "                df['user_id'][j] = l.index(i) + 1\n",
    "                \n",
    "    df_user = pd.get_dummies(df, columns = ['C1', 'banner'])\n",
    "    df_user1 = df_user.drop(columns = ['device_id','item_id'])\n",
    "    user_features = df_user1.columns.values.tolist()\n",
    "    cols = user_features\n",
    "    cols.remove('click')\n",
    "    cols.remove('id')\n",
    "    \n",
    "    # merge得到相应的数据\n",
    "    df_data = pd.read_csv(path, usecols=[0,1,11],header=0,names=['id','click','device_id'])\n",
    "    df_data['id'] = df['id']\n",
    "    df_data['user_id'] = None\n",
    "    df_data['user_id'] = df['user_id']\n",
    "    \n",
    "    train,test = train_test_split(df_data, test_size = 0.1, random_state = 666)\n",
    "    \n",
    "    label_l = ['id', 'click', 'user_id']\n",
    "    df_train = train.merge(df_user1, on = label_l, how = 'left')\n",
    "    df_test = test.merge(df_user1, on = label_l, how = 'left')\n",
    "    \n",
    "    # 转换label\n",
    "    dic = {}\n",
    "    label_set = sorted(set(df_train['click']) | set(df_test['click']))\n",
    "    \n",
    "    for label in label_set:\n",
    "        dic[label] = dic.get(label, len(dic))\n",
    "        \n",
    "    df_train['click'] = df_train[\"click\"].apply(lambda x: 1 if int(x) == 1 else 0)\n",
    "    df_test['click'] = df_test[\"click\"].apply(lambda x: 1 if int(x) == 1 else 0)\n",
    "\n",
    "    # 转化格式\n",
    "    train_labels = np.array(df_train['click'].astype(np.int32))\n",
    "    test_labels = np.array(df_test['click'].astype(np.int32))\n",
    "    \n",
    "    return df_test, df_train[cols].values, train_labels, df_test[cols].values, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM_layer(nn.Module):\n",
    "    def __init__(self, reg_l1 = 0.01, reg_l2 = 0.01, class_num = 1, feature_num = 10, latent_factor_dim = 5):\n",
    "        super().__init__()\n",
    "        self.reg_l1 = reg_l1\n",
    "        self.reg_l2 = reg_l2\n",
    "        self.k = latent_factor_dim\n",
    "        self.class_num = class_num\n",
    "        self.fea_num = feature_num\n",
    "        self.linear = nn.Linear(self.fea_num, class_num)\n",
    "        self.v = nn.Parameter(torch.randn(self.fea_num, self.k, class_num))\n",
    "        \n",
    "    def forward(self, xx):\n",
    "        linear_part = self.linear(xx)\n",
    "\n",
    "        p1 = torch.matmul(self.v.permute(2, 1, 0), xx.T).permute(2, 1, 0)\n",
    "        p1 = torch.pow(p1, 2)\n",
    "        p1 = 0.5 * torch.sum(p1, dim=1)\n",
    "        p1 = torch.squeeze(p1, dim=1)\n",
    "\n",
    "        sq1 = torch.pow(xx, 2)\n",
    "        sq2 = torch.pow(self.v, 2)\n",
    "        \n",
    "        p2 = torch.matmul(sq2.permute(2, 1, 0), sq1.T).permute(2, 1, 0)\n",
    "        p2 = torch.sum(p2, dim = 1) * -0.5\n",
    "        p2 = torch.squeeze(p2, dim = 1)\n",
    "\n",
    "        output = linear_part + p1 + p2\n",
    "\n",
    "        output = F.log_softmax(output, dim = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for idx, (x, y) in enumerate(train):\n",
    "        x = x.to(device, dtype = torch.float32)\n",
    "        y = y.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        \n",
    "        if model.class_num == 2:\n",
    "            loss = F.cross_entropy(output, y)\n",
    "        else:\n",
    "            loss = F.nll_loss(output, y)\n",
    "\n",
    "        loss1 = 0\n",
    "        for param in model.parameters():\n",
    "            loss1 += model.reg_l1 * torch.sum(torch.abs(param))\n",
    "            loss1 += model.reg_l2 * torch.sum(torch.pow(param, 2))\n",
    "        loss += loss1\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, device, test):\n",
    "    loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test:\n",
    "            x = x.to(device, dtype = torch.float32)\n",
    "            y = y.to(device).long()\n",
    "            output = model(x)\n",
    "\n",
    "            if model.class_num == 2:\n",
    "                loss += F.cross_entropy(output, y)\n",
    "            else:\n",
    "                loss += F.nll_loss(output, y, reduction='sum').item()\n",
    "\n",
    "            loss1 = 0\n",
    "            for param in model.parameters():\n",
    "                loss1 += model.reg_l1 * torch.sum(torch.abs(param))\n",
    "                loss1 += model.reg_l2 * torch.sum(torch.pow(param, 2))\n",
    "            loss += loss1\n",
    "            pred = output.max(1, keepdim = True)[1]\n",
    "            corr += pred.eq(y.view_as(pred)).sum().item()\n",
    "            \n",
    "    loss /= len(test.dataset)\n",
    "    \n",
    "    print(\"loss:\" + str(loss.item()) + \" acc:\" + str(100. * corr / len(test.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(model,use,device,df_test,data_loader):\n",
    "    dic = {}\n",
    "    l = []\n",
    "    labels = []\n",
    "    predicts = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x = x.to(device, dtype = torch.float32)\n",
    "            y = y.to(device).long()\n",
    "            pre = model(x).max(1, keepdim = True)[0]\n",
    "            \n",
    "            for i in range(len(pre)):\n",
    "                l.append([list(df_test['device_id'])[i], list(df_test['id'])[i], pre[i], y[i]])\n",
    "                \n",
    "            for user, item, pre, label in l:\n",
    "                if int(label) == 1: #如果点击过就跳过 \n",
    "                    continue\n",
    "                dic.setdefault(user, {})\n",
    "                pre = float(pre)\n",
    "                dic[user].setdefault(item, pre)\n",
    "                \n",
    "    l = list(sorted(dic[use].items(), key = itemgetter(1), reverse = True)[:5])\n",
    "    \n",
    "    return [x[0] for x in l]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Ksoftware\\anacondanew\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# 导入数据\n",
    "path = './data/avazu/ctr_data.csv'\n",
    "df_test, x_train, y_train, x_test, y_test = load_dataset(path)\n",
    "\n",
    "x_train = preprocessing.scale(x_train, with_mean = True, with_std = True)\n",
    "x_test = preprocessing.scale(x_test, with_mean = True, with_std = True)\n",
    "\n",
    "l1 = [x for x in y_train]\n",
    "l2 = [x for x in y_test]\n",
    "l = set(l1 + l2)\n",
    "class_num = len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.022671567276120186 acc:81.0\n",
      "loss:0.021910198032855988 acc:81.0\n",
      "loss:0.02117926813662052 acc:81.1\n",
      "loss:0.020533064380288124 acc:81.4\n",
      "loss:0.0199109073728323 acc:81.5\n",
      "loss:0.01929924078285694 acc:81.5\n",
      "loss:0.01869148202240467 acc:81.5\n",
      "loss:0.01813225820660591 acc:81.6\n",
      "loss:0.017603997141122818 acc:81.5\n",
      "loss:0.017184050753712654 acc:81.7\n"
     ]
    }
   ],
   "source": [
    "# FM模型\n",
    "model = FM_layer(class_num = class_num, feature_num = x_train.shape[1], latent_factor_dim = 40).to(device)\n",
    "\n",
    "# 定义损失函数还有优化器\n",
    "optm = torch.optim.Adam(model.parameters())\n",
    "train_data = get_data(x_train, y_train, batch_size, shuffle = True)\n",
    "test_data = get_data(x_test, y_test, batch_size, shuffle = False)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    train_model(model, device, train_data, optm, epoch + 1)\n",
    "    test_model(model, device, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10881712716703200000, 11048385866036000000, 10955087334956200000, 10120198792268400000, 10686482616237200000]\n"
     ]
    }
   ],
   "source": [
    "l = recommend(model, \"a99f214a\", device, df_test, test_data)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

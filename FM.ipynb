{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入相应的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from operator import itemgetter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固定随机数种子，保证模型的可复现性\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 1024\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(xx, yy, batch_size, shuffle):\n",
    "    class newDataset(data.Dataset):\n",
    "        def __init__(self, xx, yy):\n",
    "            self.xx = xx\n",
    "            self.yy = yy\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            m, n = self.xx[index], self.yy[index]\n",
    "            return m, n\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.xx)\n",
    "\n",
    "    bdata = data.DataLoader(newDataset(xx, yy), batch_size = batch_size, shuffle = shuffle)\n",
    "    \n",
    "    return bdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, usecols = [0, 1, 11, 3, 4], header = 0, names = ['id', 'click', 'C1', 'banner', 'device_id'])\n",
    "    # 处理\n",
    "    df[\"user_id\"] = None\n",
    "    df[\"item_id\"] = df[\"id\"]\n",
    "    l = list(set(df['device_id']))\n",
    "    \n",
    "    for i in l:\n",
    "        for j in range(0, len(df['device_id'])):\n",
    "            if df['device_id'][j] == i:\n",
    "                df['user_id'][j] = l.index(i) + 1\n",
    "                \n",
    "    df_one_hot = pd.get_dummies(df, columns = ['C1', 'banner']) # one_hot\n",
    "    \n",
    "    df_use = df_one_hot.drop(columns = ['device_id','item_id'])\n",
    "    feature = df_use.columns.values.tolist()\n",
    "    new_feature = feature\n",
    "    drop_feature = [\"click\", \"id\"]\n",
    "    for i in drop_feature:\n",
    "        new_feature.remove(i)\n",
    "    \n",
    "    # merge得到相应的数据\n",
    "    label = ['id', 'click', 'device_id']\n",
    "    df_data = pd.read_csv(path, usecols = [0, 1, 11], header = 0, names = label)\n",
    "    df_data['id'] = df['id']\n",
    "    df_data['user_id'] = None\n",
    "    df_data['user_id'] = df['user_id']\n",
    "    train, test = train_test_split(df_data, test_size = 0.1) # 划分训练集和测试集\n",
    "    \n",
    "    label_l = ['id', 'click', 'user_id']\n",
    "    df_train = train.merge(df_use, on = label_l, how = 'left')\n",
    "    df_test = test.merge(df_use, on = label_l, how = 'left')\n",
    "    \n",
    "    # 转换label\n",
    "    dic = {}\n",
    "    label_set = sorted(set(df_train['click']) | set(df_test['click']))\n",
    "    \n",
    "    for label in label_set:\n",
    "        dic[label] = dic.get(label, len(dic))\n",
    "        \n",
    "    df_train['click'] = df_train[\"click\"].apply(lambda x: 1 if int(x) == 1 else 0)\n",
    "    df_test['click'] = df_test[\"click\"].apply(lambda x: 1 if int(x) == 1 else 0)\n",
    "\n",
    "    # 转化格式\n",
    "    train_labels = np.array(df_train['click'].astype(np.int32))\n",
    "    test_labels = np.array(df_test['click'].astype(np.int32))\n",
    "    \n",
    "    return df_test, df_train[new_feature].values, train_labels, df_test[new_feature].values, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM_layer(nn.Module):\n",
    "    def __init__(self, reg_l1 = 0.01, reg_l2 = 0.01, class_num = 1, feature_num = 10, latent_factor_dim = 5):\n",
    "        super().__init__()\n",
    "        self.k = latent_factor_dim\n",
    "        self.class_num = class_num\n",
    "        self.fea_num = feature_num\n",
    "        self.reg_l1 = reg_l1\n",
    "        self.reg_l2 = reg_l2\n",
    "        self.linear = nn.Linear(self.fea_num, class_num)\n",
    "        self.v = nn.Parameter(torch.randn(self.fea_num, self.k, class_num))\n",
    "        \n",
    "    def forward(self, xx):\n",
    "        lp = self.linear(xx)\n",
    "\n",
    "        p1 = torch.matmul(self.v.permute(2, 1, 0), xx.T).permute(2, 1, 0)\n",
    "        p1 = torch.pow(p1, 2)\n",
    "        p1 = 0.5 * torch.sum(p1, dim=1)\n",
    "        p1 = torch.squeeze(p1, dim=1)\n",
    "\n",
    "        sq1 = torch.pow(xx, 2)\n",
    "        sq2 = torch.pow(self.v, 2)\n",
    "        \n",
    "        p2 = torch.matmul(sq2.permute(2, 1, 0), sq1.T).permute(2, 1, 0)\n",
    "        p2 = torch.sum(p2, dim = 1) * -0.5\n",
    "        p2 = torch.squeeze(p2, dim = 1)\n",
    "\n",
    "        output = lp + p1 + p2\n",
    "\n",
    "        output = F.log_softmax(output, dim = 1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for idx, (x, y) in enumerate(train):\n",
    "        x = x.to(device, dtype = torch.float32)\n",
    "        y = y.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        \n",
    "        if model.class_num == 2:\n",
    "            loss = F.cross_entropy(output, y)\n",
    "        else:\n",
    "            loss = F.nll_loss(output, y)\n",
    "\n",
    "        loss1 = 0\n",
    "        for param in model.parameters():\n",
    "            loss1 += model.reg_l1 * torch.sum(torch.abs(param))\n",
    "            loss1 += model.reg_l2 * torch.sum(torch.pow(param, 2))\n",
    "        loss += loss1\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, device, test):\n",
    "    loss = 0\n",
    "    corr = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test:\n",
    "            x = x.to(device, dtype = torch.float32)\n",
    "            y = y.to(device).long()\n",
    "            output = model(x)\n",
    "\n",
    "            if model.class_num == 2:\n",
    "                loss += F.cross_entropy(output, y)\n",
    "            else:\n",
    "                loss += F.nll_loss(output, y, reduction='sum').item()\n",
    "\n",
    "            loss1 = 0\n",
    "            for param in model.parameters():\n",
    "                loss1 += model.reg_l1 * torch.sum(torch.abs(param))\n",
    "                loss1 += model.reg_l2 * torch.sum(torch.pow(param, 2))\n",
    "            loss += loss1\n",
    "            \n",
    "            pred = output.max(1, keepdim = True)[1]\n",
    "            corr += pred.eq(y.view_as(pred)).sum().item()\n",
    "            \n",
    "    loss /= len(test.dataset)\n",
    "    print(\"loss:\" + str(loss.item()) + \" acc:\" + str( corr / len(test.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(model, use_id, device, df_test, data):\n",
    "    dic = {}\n",
    "    l = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in data:\n",
    "            x = x.to(device, dtype = torch.float32)\n",
    "            y = y.to(device).long()\n",
    "            pre = model(x).max(1, keepdim = True)[0]\n",
    "            \n",
    "            for i in range(0, len(pre)):\n",
    "                l.append([list(df_test['device_id'])[i], list(df_test['id'])[i], pre[i], y[i]])\n",
    "                \n",
    "            for user, item, pre, label in l:\n",
    "                if int(label) == 1: #如果点击过就跳过 \n",
    "                    continue\n",
    "                dic.setdefault(user, {})\n",
    "                pre = float(pre)\n",
    "                dic[user].setdefault(item, pre)\n",
    "                \n",
    "    l = list(sorted(dic[use_id].items(), key = itemgetter(1), reverse = True)[:5])\n",
    "    \n",
    "    return [x[0] for x in l]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Ksoftware\\anacondanew\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# 导入数据\n",
    "path = './data/avazu/ctr_data.csv'\n",
    "df_test, x_train, y_train, x_test, y_test = load_dataset(path)\n",
    "\n",
    "x_train = preprocessing.scale(x_train, with_mean = True, with_std = True)\n",
    "x_test = preprocessing.scale(x_test, with_mean = True, with_std = True)\n",
    "\n",
    "l1 = [x for x in y_train]\n",
    "l2 = [x for x in y_test]\n",
    "l = set(l1 + l2)\n",
    "class_num = len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.022308453917503357 acc:0.808\n",
      "loss:0.021703263744711876 acc:0.808\n",
      "loss:0.021083194762468338 acc:0.808\n",
      "loss:0.02048397809267044 acc:0.806\n",
      "loss:0.01989045739173889 acc:0.806\n",
      "loss:0.01929497718811035 acc:0.805\n",
      "loss:0.018714744597673416 acc:0.805\n",
      "loss:0.01812630519270897 acc:0.805\n",
      "loss:0.01756555587053299 acc:0.806\n",
      "loss:0.017086299136281013 acc:0.807\n"
     ]
    }
   ],
   "source": [
    "# FM模型\n",
    "model = FM_layer(class_num = class_num, feature_num = x_train.shape[1], latent_factor_dim = 40).to(device)\n",
    "\n",
    "# 定义损失函数还有优化器\n",
    "optm = torch.optim.Adam(model.parameters())\n",
    "train_data = get_data(x_train, y_train, batch_size, shuffle = True)\n",
    "test_data = get_data(x_test, y_test, batch_size, shuffle = False)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    train_model(model, device, train_data, optm, epoch + 1)\n",
    "    test_model(model, device, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10888676745574100000, 11083904333730300000, 11277485828613800000, 10064037090970500000, 1102755678399120000]\n"
     ]
    }
   ],
   "source": [
    "l = recommend(model, \"a99f214a\", device, df_test, test_data)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
